{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BAGAN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptran1203/gan_project/blob/master/notebooks/BAGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0um8W2D9js7",
        "colab_type": "text"
      },
      "source": [
        "## Create the link from this drive folder to your drive.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "https://drive.google.com/drive/folders/1RNJXceXkNatuAbNn-CKB8MrgaEHG5RpM?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqAhBY2Qm7M7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c31fa0d7-e736-42bb-9247-40dd12acee5e"
      },
      "source": [
        "cd /content"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gYUSJ8pnoJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from google.colab import drive, output\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!rm -rf '/content/gan_project'\n",
        "!git clone https://github.com/ptran1203/gan_project\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "output.clear()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-ekhuj6nrNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e952bc3-941a-40b6-b395-c14d793007db"
      },
      "source": [
        "cd gan_project"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gan_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oImN0Awnnurt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "30651182-eef4-4b81-b527-637d725f03c7"
      },
      "source": [
        "BASE_DIR = '/content/drive/My Drive/bagan'\n",
        "DS_DIR = '/content/drive/My Drive/bagan/dataset/chest_xray'\n",
        "DS_SAVE_DIR = '/content/drive/My Drive/bagan/dataset/save'\n",
        "gratio_mode = 'uniform'\n",
        "dratio_mode = 'uniform'\n",
        "\n",
        "from bagan import *\n",
        "from batch_gen import *\n",
        "from utils import *\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "\n",
        "def create_dir_if_any(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "class Bagan(BalancingGAN):\n",
        "    def _build_common_encoder(self, image, min_latent_res=8):\n",
        "        resolution = self.resolution\n",
        "        channels = self.channels\n",
        "\n",
        "        # build a relatively standard conv net, with LeakyReLUs as suggested in ACGAN\n",
        "        cnn = Sequential()\n",
        "\n",
        "        cnn.add(Conv2D(128, (5, 5), padding='same', strides=(2, 2)))\n",
        "        cnn.add(LeakyReLU(alpha=0.2))\n",
        "        cnn.add(Dropout(0.3))\n",
        "            \n",
        "        cnn.add(Conv2D(256, (5, 5), padding='same', strides=(2, 2)))\n",
        "        cnn.add(LeakyReLU(alpha=0.2))\n",
        "        cnn.add(Dropout(0.3))\n",
        "\n",
        "        cnn.add(Conv2D(512, (5, 5), padding='same', strides=(2, 2)))\n",
        "        cnn.add(LeakyReLU(alpha=0.2))\n",
        "        cnn.add(Dropout(0.3))\n",
        "\n",
        "        cnn.add(Flatten())\n",
        "\n",
        "        features = cnn(image)\n",
        "        return features\n",
        "\n",
        "    # def backup_point(self, epoch): return\n",
        "\n",
        "\n",
        "class BatchGen(BatchGenerator):\n",
        "    to_train_classes = INVERT_CATEGORIES_MAP[:2]\n",
        "    to_test_classes = list(range(81, 86))\n",
        "\n",
        "\n",
        "is_test = 0\n",
        "## Test batch GEN\n",
        "if is_test:\n",
        "    bg = BatchGen(BatchGen.TRAIN, 64, 'multi_chest', 64)\n",
        "    labels = np.array([0, 0, 1, 1, 2, 2, 3 ,1])\n",
        "    samples = bg.ramdom_kshot_images(4, labels)\n",
        "    print(samples.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh60L-YIn7JG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan_epochs  = 400000\n",
        "adam_lr = 0.00002\n",
        "batch_size = 128\n",
        "# dataset_name should be \"flowers\", \"chest\", \"multi_chest\"\n",
        "# \"chest\" is binary classification, \"multi_chest\" using chest-xray14 dataset\n",
        "dataset_name = 'multi_chest'\n",
        "latent_size = 128\n",
        "# Use resnet architecture for Generator\n",
        "resnet = False\n",
        "# Use self-attention mechanism\n",
        "attention = False\n",
        "np.random.seed(0)\n",
        "# Image resoulution\n",
        "rst = 64\n",
        "is_prune = False\n",
        "\n",
        "prune = [900, 900] if is_prune else None\n",
        "\n",
        "res_dir = BASE_DIR + '/result/bagan_{}_{}_v2'.format(dataset_name,rst)\n",
        "create_dir_if_any(res_dir)\n",
        "\n",
        "bg_train_full = BatchGen(BatchGen.TRAIN, batch_size, dataset_name, rst,prune_classes=prune)\n",
        "bg_test = BatchGen(BatchGen.TEST, batch_size, dataset_name, rst)\n",
        "channels = bg_train_full.dataset_x[0].shape[-1]\n",
        "shape = bg_train_full.dataset_x[0].shape\n",
        "\n",
        "print('img shape', shape)\n",
        "classes = bg_train_full.get_label_table()\n",
        "target_classes = np.array(range(len(classes)))\n",
        "target_class_id = 0 # train to balance this class\n",
        "print('Class counters: ', bg_train_full.per_class_count)\n",
        "gan = Bagan(\n",
        "    target_classes,\n",
        "    target_class_id,\n",
        "    adam_lr=adam_lr,\n",
        "    latent_size=latent_size,\n",
        "    res_dir=res_dir,\n",
        "    image_shape=shape,\n",
        "    min_latent_res=4,\n",
        "    autoenc_epochs=50\n",
        ")\n",
        "gan.train(bg_train_full, bg_test, epochs=gan_epochs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20dRojXM2ohB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(latent_size, init_resolution=8):\n",
        "        resolution = 64\n",
        "        channels = 1\n",
        "        init_channels = 256\n",
        "        cnn = Sequential()\n",
        "\n",
        "        cnn.add(Dense(init_channels * init_resolution * init_resolution, input_dim=latent_size))\n",
        "        cnn.add(BatchNormalization())\n",
        "        cnn.add(LeakyReLU())\n",
        "        cnn.add(Reshape((init_resolution, init_resolution, init_channels)))\n",
        "       \n",
        "        crt_res = init_resolution\n",
        "        # upsample\n",
        "        while crt_res < resolution/2:\n",
        "            cnn.add(Conv2DTranspose(\n",
        "                init_channels, kernel_size = 5, strides = 2, padding='same'))\n",
        "            cnn.add(LeakyReLU(alpha=0.02))\n",
        "            init_channels //= 2\n",
        "            crt_res = crt_res * 2\n",
        "            assert crt_res <= resolution,\\\n",
        "                \"Error: final resolution [{}] must equal i*2^n. Initial resolution i is [{}]. n must be a natural number.\".format(resolution, init_resolution)\n",
        "        cnn.add(Conv2DTranspose(\n",
        "                    1, kernel_size = 5,\n",
        "                    strides = 2, padding='same',\n",
        "                    activation='tanh'))\n",
        "\n",
        "        latent = Input(shape=(latent_size, ))\n",
        "\n",
        "        fake_image_from_latent = cnn(latent)\n",
        "        return Model(inputs=latent, outputs=fake_image_from_latent)\n",
        "\n",
        "model = build_generator(128, 4)\n",
        "model.layers[1].summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}