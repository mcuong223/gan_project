{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BAGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptran1203/gan_project/blob/master/notebooks/BAGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0um8W2D9js7",
        "colab_type": "text"
      },
      "source": [
        "## Create the link from this drive folder to your drive.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "https://drive.google.com/drive/folders/1RNJXceXkNatuAbNn-CKB8MrgaEHG5RpM?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqAhBY2Qm7M7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3428b570-d126-4fb5-9d0f-1cf5eea0849c"
      },
      "source": [
        "cd /content"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gYUSJ8pnoJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from google.colab import drive, output\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!rm -rf '/content/gan_project'\n",
        "!git clone https://github.com/ptran1203/gan_project\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "output.clear()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-ekhuj6nrNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16fbe90e-1684-4e1d-a75a-d9dd63258b5a"
      },
      "source": [
        "cd gan_project"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gan_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oImN0Awnnurt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "376fffdb-2fa7-4a8f-d81c-426dde03a8c8"
      },
      "source": [
        "BASE_DIR = '/content/drive/My Drive/bagan'\n",
        "DS_DIR = '/content/drive/My Drive/bagan/dataset/chest_xray'\n",
        "DS_SAVE_DIR = '/content/drive/My Drive/bagan/dataset/save'\n",
        "gratio_mode = 'uniform'\n",
        "dratio_mode = 'uniform'\n",
        "\n",
        "from bagan import *\n",
        "from batch_gen import *\n",
        "from utils import *\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "\n",
        "def create_dir_if_any(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "class Bagan(BalancingGAN):\n",
        "    pass\n",
        "\n",
        "    # def backup_point(self, epoch): return\n",
        "\n",
        "\n",
        "class BatchGen(BatchGenerator):\n",
        "    to_train_classes = INVERT_CATEGORIES_MAP\n",
        "    to_test_classes = list(range(81, 86))\n",
        "\n",
        "\n",
        "is_test = 0\n",
        "## Test batch GEN\n",
        "if is_test:\n",
        "    bg = BatchGen(BatchGen.TRAIN, 64, 'multi_chest', 64)\n",
        "    labels = np.array([0, 0, 1, 1, 2, 2, 3 ,1])\n",
        "    samples = bg.ramdom_kshot_images(4, labels)\n",
        "    print(samples.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh60L-YIn7JG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "5b0687e8-91f9-43d6-8153-995c0aecc008"
      },
      "source": [
        "gan_epochs  = 400000\n",
        "adam_lr = 0.00002\n",
        "batch_size = 64\n",
        "# dataset_name should be \"flowers\", \"chest\", \"multi_chest\"\n",
        "# \"chest\" is binary classification, \"multi_chest\" using chest-xray14 dataset\n",
        "dataset_name = 'multi_chest'\n",
        "latent_size = 128\n",
        "# Use resnet architecture for Generator\n",
        "resnet = False\n",
        "# Use self-attention mechanism\n",
        "attention = False\n",
        "np.random.seed(0)\n",
        "# Image resoulution\n",
        "rst = 128\n",
        "is_prune = False\n",
        "\n",
        "prune = [900, 900] if is_prune else None\n",
        "\n",
        "res_dir = BASE_DIR + '/result/bagan_{}_{}_v2'.format(dataset_name,rst)\n",
        "create_dir_if_any(res_dir)\n",
        "\n",
        "bg_train_full = BatchGen(BatchGen.TRAIN, batch_size, dataset_name, rst,prune_classes=prune)\n",
        "bg_test = BatchGen(BatchGen.TEST, batch_size, dataset_name, rst)\n",
        "channels = bg_train_full.dataset_x[0].shape[-1]\n",
        "shape = bg_train_full.dataset_x[0].shape\n",
        "\n",
        "print('img shape', shape)\n",
        "classes = bg_train_full.get_label_table()\n",
        "target_classes = np.array(range(len(classes)))\n",
        "target_class_id = 0 # train to balance this class\n",
        "print('Class counters: ', bg_train_full.per_class_count)\n",
        "gan = Bagan(\n",
        "    target_classes,\n",
        "    target_class_id,\n",
        "    adam_lr=adam_lr,\n",
        "    latent_size=latent_size,\n",
        "    res_dir=res_dir,\n",
        "    image_shape=shape,\n",
        "    min_latent_res=4,\n",
        "    autoenc_epochs=50\n",
        ")\n",
        "gan.train(bg_train_full, bg_test, epochs=gan_epochs)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "load data from /content/drive/My Drive/bagan/dataset/multi_chest/imgs_labels_128.pkl successfully\n",
            "15830 15830\n",
            "load data from /content/drive/My Drive/bagan/dataset/multi_chest/imgs_labels_128.pkl successfully\n",
            "15830 15830\n",
            "img shape (128, 128, 1)\n",
            "Class counters:  [5000, 3341, 1475, 1384, 946, 767, 748, 458, 394, 382, 312, 254, 219, 112, 38]\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "BAGAN init_autoenc\n",
            "BAGAN: training autoencoder\n",
            "Autoencoder train epoch: 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Autoencoder train epoch: 2/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-03170c0f5a9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mautoenc_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m )\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbg_train_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgan_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/gan_project/bagan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, bg_train, bg_test, epochs)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0;31m# Initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BAGAN init_autoenc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_autoenc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbg_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BAGAN autoenc initialized, init gan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0mstart_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gan_project/bagan.py\u001b[0m in \u001b[0;36minit_autoenc\u001b[0;34m(self, bg_train, gen_fname, rec_fname)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbg_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                     \u001b[0mautoenc_train_loss_crt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoenc_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m                 \u001b[0mautoenc_train_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoenc_train_loss_crt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn8P7I24j0oO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size = 1000 # images in each class\n",
        "labels = [0] * size\n",
        "for i in range(1, gan.nclasses):\n",
        "    labels += [i] * size \n",
        "\n",
        "labels = np.array(labels)\n",
        "fakes = gan.generate(labels)\n",
        "show_samples(fakes[:10])\n",
        "res = (fakes, labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQPfNLoGN1Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_g(self, test_x, test_y):\n",
        "    y_pre = self.combined.predict(test_x)\n",
        "    y_pre = np.argmax(y_pre, axis=1)\n",
        "    cm = metrics.confusion_matrix(y_true=test_y, y_pred=y_pre)  # shape=(12, 12)\n",
        "    plt.figure()\n",
        "    plot_confusion_matrix(cm, hide_ticks=True,cmap=plt.cm.Blues)\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_d(self, test_x, test_y):\n",
        "    y_pre = self.discriminator.predict(test_x)\n",
        "    y_pre = np.argmax(y_pre, axis=1)\n",
        "    cm = metrics.confusion_matrix(y_true=test_y, y_pred=y_pre)  # shape=(12, 12)\n",
        "    plt.figure()\n",
        "    plot_confusion_matrix(cm, hide_ticks=True,cmap=plt.cm.Blues)\n",
        "    plt.show()\n",
        "\n",
        "train_x, train_y = bg_train_full.dataset_x, bg_train_full.dataset_y\n",
        "# train_y = train_y[:10]\n",
        "# latent = gan.generate_latent(train_y)\n",
        "# evaluate_g(gan, latent, train_y)\n",
        "# evaluate_d(gan, train_x, train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdWe0-vQBAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate image for data augmentation\n",
        "def gen_for_class(self, bg, classid,size=1000):\n",
        "    total = None\n",
        "    for i in range(1000):\n",
        "        labels = [classid] * size\n",
        "        labels = np.array(labels)\n",
        "        latent = self.generate_latent(labels)\n",
        "        print(\"Predict...\")\n",
        "        gen = self.generator.predict(latent)\n",
        "        d_outputs = self.discriminator.predict(gen)\n",
        "        d_outputs = np.argmax(d_outputs, axis=1)\n",
        "        print(Counter(d_outputs))\n",
        "        to_keep = np.where(labels == d_outputs)[0]\n",
        "        gen = gen[to_keep]\n",
        "        if total is None:\n",
        "            total = gen\n",
        "        else:\n",
        "            total = np.concatenate([total, gen], axis=0)\n",
        "        \n",
        "        if len(total) >= size:\n",
        "            total = total[:size]\n",
        "            break\n",
        "\n",
        "    print(\"done class {}, size {}\".format(classid, len(total)))\n",
        "    return total, np.array([classid] * len(total))\n",
        "\n",
        "def gen_augment_data(self, bg, size=1000):\n",
        "    total = None\n",
        "    labels = None\n",
        "    for i in bg.classes:\n",
        "        gen , label = gen_for_class(self,bg, i, size)\n",
        "        if total is None:\n",
        "            total = gen\n",
        "            labels = label\n",
        "        else:\n",
        "            total = np.concatenate([total, gen], axis=0)\n",
        "            labels = np.concatenate([labels, label], axis=0)\n",
        "    \n",
        "    print(\"Done all \", len(total))\n",
        "    return total, labels\n",
        "fakes = gen_augment_data(gan, bg_train_full,2000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wocq1KzjaEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_samples(fakes[0][:10])\n",
        "pickle_save(fakes, '/content/drive/My Drive/bagan/dataset/multi_chest/imgs_train_gen_v3.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}